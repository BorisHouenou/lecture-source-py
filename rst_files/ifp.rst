.. _ifp:

.. include:: /_static/includes/lecture_howto_py.raw

.. highlight:: python3

********************************************************************
:index:`Optimal Savings III: Occasionally Binding Constraints`
********************************************************************

.. contents:: :depth: 2

Overview
============

Next we study an optimal savings problem for an infinitely lived consumer---the "common ancestor" described in :cite:`Ljungqvist2012`, section 1.3

This is an essential sub-problem for many representative macroeconomic models

* :cite:`Aiyagari1994`

* :cite:`Huggett1993`

* etc.

It is related to the decision problem in the :doc:`stochastic optimal growth
model <optgrowth>` and yet differs in important ways

For example, the choice problem for the agent includes an additive income term that leads to an occasionally binding constraint

Our presentation of the model will be relatively brief

.. only:: html

    * For further details on economic intuition, implication and models, see :cite:`Ljungqvist2012`
    * Proofs of all mathematical results stated below can be found in :download:`this paper </_static/pdfs/pi2.pdf>`

.. only:: latex

    * For further details on economic intuition, implication and models, see :cite:`Ljungqvist2012`
    * Proofs of all mathematical results stated below can be found in `this paper <https://lectures.quantecon.org/_downloads/pi2.pdf>`__

To solve the model we will use Euler equation based time iteration, similar to :doc:`this lecture <coleman_policy_iter>`

This method turns out to be

* Globally convergent under mild assumptions, even when utility is unbounded (both above and below)

* More efficient numerically than value function iteration



References
----------------

Other useful references include :cite:`Deaton1991`, :cite:`DenHaan2010`, :cite:`Kuhn2013`, :cite:`Rabault2002`,  :cite:`Reiter2009`  and :cite:`SchechtmanEscudero1977`


The Optimal Savings Problem
===============================

.. index::
    single: Optimal Savings; Problem

Let's write down the model and then discuss how to solve it

Set Up
---------

Consider a household that chooses a state-contingent consumption plan :math:`\{c_t\}_{t \geq 0}` to maximize

.. math::

    \mathbb{E} \, \sum_{t=0}^{\infty} \beta^t u(c_t)


subject to

.. math::
    :label: eqst

    c_t + a_{t+1} \leq  Ra_t  + z_t,
    \qquad c_t \geq 0,
    \qquad a_t \geq -b
    \qquad t = 0, 1, \ldots


Here

* :math:`\beta \in (0,1)` is the discount factor

* :math:`a_t` is asset holdings at time :math:`t`, with ad-hoc borrowing constraint :math:`a_t \geq -b`

* :math:`c_t` is consumption

* :math:`z_t` is non-capital income (wages, unemployment compensation, etc.)

* :math:`R := 1 + r`, where :math:`r > 0` is the interest rate on savings


Non-capital income :math:`\{z_t\}` is assumed to be a Markov process taking values in :math:`Z\subset (0,\infty)` with stochastic kernel :math:`\Pi` 

This means that :math:`\Pi(z, B)` is the probability that :math:`z_{t+1} \in
B` given :math:`z_t = z`

The expectation of :math:`f(z_{t+1})` given :math:`z_t = z` is written as

.. math::

    \int f( \acute z) \, \Pi(z, d \acute z)

We further assume that

#. :math:`r > 0` and :math:`\beta R < 1`

#. :math:`u` is smooth, strictly increasing and strictly concave with :math:`\lim_{c \to 0} u'(c) = \infty` and :math:`\lim_{c \to \infty} u'(c) = 0`



The asset space is :math:`[-b, \infty)` and the state is the pair :math:`(a,z) \in S := [-b,\infty) \times Z`

A *feasible consumption path* from :math:`(a,z) \in S` is a consumption
sequence :math:`\{c_t\}` such that :math:`\{c_t\}` and its induced asset path :math:`\{a_t\}` satisfy

#. :math:`(a_0, z_0) = (a, z)`

#. the feasibility constraints in :eq:`eqst`, and

#. measurability of :math:`c_t` w.r.t. the filtration generated by :math:`\{z_1, \ldots, z_t\}`

The meaning of the third point is just that consumption at time :math:`t` can only be
a function of outcomes that have already been observed


Value Function and Euler Equation
------------------------------------

The *value function* :math:`V \colon S \to \mathbb{R}` is defined by

.. math::
    :label: eqvf

    V(a, z) := \sup \, \mathbb{E}
    \left\{
    \sum_{t=0}^{\infty} \beta^t u(c_t)
    \right\}


where the supremum is over all feasible consumption paths from :math:`(a,z)`.


An *optimal consumption path* from :math:`(a,z)` is a feasible consumption path from :math:`(a,z)` that attains the supremum in :eq:`eqvf`

To pin down such paths we can use a version of the Euler equation, which in the present setting is

.. math::
    :label: ee00

    u' (c_t)
    \geq \beta R \,  \mathbb{E}_t [ u'(c_{t+1}) ] 

and

.. math::
    :label: ee01

    u' (c_t) = \beta R \,  \mathbb{E}_t [ u'(c_{t+1}) ] 
    \quad \text{whenever }
    c_t < Ra_t + z_t + b

In essence, this says that the natural "arbitrage" relation :math:`u' (c_t) = \beta R \,  \mathbb{E}_t [ u'(c_{t+1}) ]` holds when the choice of current consumption is interior

Interiority means that :math:`c_t` is strictly less than its upper bound :math:`Ra_t + z_t + b`

(The lower boundary case :math:`c_t = 0` never arises at the optimum because
:math:`u'(0) = \infty`)

When :math:`c_t` does hit the upper bound :math:`Ra_t + z_t + b`, the 
strict inequality :math:`u' (c_t) > \beta R \,  \mathbb{E}_t [ u'(c_{t+1}) ]`
can occur because :math:`c_t` cannot increase sufficiently to attain equality


With some thought and effort, one can show that :eq:`ee00` and :eq:`ee01` are
equivalent to

.. math::
    :label: eqeul0

    u' (c_t)
    = \max \left\{
    \beta R \,  \mathbb{E}_t [ u'(c_{t+1}) ] \,,\;  u'(Ra_t + z_t + b)
    \right\}


Optimality Results
------------------


.. only:: html

    Given our assumptions, it is :download:`known </_static/pdfs/pi2.pdf>` that

.. only:: latex

    Given our assumptions, it is `known <https://lectures.quantecon.org/_downloads/pi2.pdf>`__ that


#. For each :math:`(a,z) \in S`, a unique optimal consumption path from :math:`(a,z)` exists

#. This path is the unique feasible path from :math:`(a,z)` satisfying the
   Euler equality :eq:`eqeul0` and the transversality condition

.. math::
    :label: eqtv

    \lim_{t \to \infty} \beta^t \, \mathbb{E} \, [ u'(c_t) a_{t+1} ] = 0.


Moreover, there exists an *optimal consumption function* 
:math:`\sigma^* \colon S \to [0, \infty)` such that the path from :math:`(a,z)` generated by

.. math::

    (a_0, z_0) = (a, z),
    \quad
    z_{t+1} \sim \Pi(z_t, dy),
    \quad
    c_t = \sigma^*(a_t, z_t)
    \quad \text{and} \quad
    a_{t+1} = R a_t + z_t - c_t


satisfies both :eq:`eqeul0` and :eq:`eqtv`, and hence is the unique optimal
path from :math:`(a,z)`

In summary, to solve the optimization problem, we need to compute :math:`\sigma^*`


.. _ifp_computation:

Computation
===============

.. index::
    single: Optimal Savings; Computation

There are two standard ways to solve for :math:`\sigma^*`

#. Time iteration (TI) using the Euler equality 

#. Value function iteration (VFI)

Let's look at these in turn

Time Iteration
-----------------------------

We can rewrite :eq:`eqeul0` to make it a statement about functions rather than
random variables

In particular, consider the functional equation

.. math::
    :label: eqeul1

    u' \circ \sigma \, (a, z)
    = \max \left\{
    \gamma \int u' \circ \sigma \, \{R a + z - c(a, z), \, \acute z\}
    \, \Pi(z,d \acute z)
    \, , \;
         u'(Ra + z + b)
         \right\}


where :math:`\gamma := \beta R` and :math:`u' \circ c(s) := u'(c(s))`

Equation :eq:`eqeul1` is a functional equation in :math:`\sigma`

In order to identify a solution, let :math:`\mathscr{C}` be the set of 
candidate consumption functions :math:`\sigma \colon S \to \mathbb R` such that

* each :math:`\sigma \in \mathscr{C}` is continuous and (weakly) increasing
* :math:`\min Z \leq c(a,z) \leq Ra + z + b` for all :math:`(a,z) \in S`

In addition, let :math:`K \colon \mathscr{C} \to \mathscr{C}` be defined as follows:

For given :math:`\sigma \in \mathscr{C}`, the value :math:`K \sigma (a,z)` is the unique :math:`t \in J(a,z)` that solves

.. math::
    :label: eqsifc

    u'(t)
    = \max \left\{
    \gamma \int u' \circ \sigma \, \{R a + z - t, \, \acute z\}
    \, \Pi(z,d \acute z)
    \, , \;
         u'(Ra + z + b)
         \right\}


where

.. math::
    :label: eqbos

    J(a,z) := \{t \in \mathbb{R} \,:\, \min Z \leq t \leq Ra+ z + b\}


We refer to :math:`K` as Coleman's policy function operator :cite:`Coleman1990`

.. only:: html

    It is :download:`known </_static/pdfs/pi2.pdf>` that

.. only:: latex

    It is `known <https://lectures.quantecon.org/_downloads/pi2.pdf>`__ that

* :math:`K` is a contraction mapping on :math:`\mathscr{C}` under the metric

.. math::

    \rho(c, d) := \| \, u' \circ \sigma_1 - u' \circ \sigma_2 \, \|
        := \sup_{s \in S} | \, u'(\sigma_1(s))  - u'(\sigma_2(s)) \, |
     \qquad \quad (\sigma_1, \sigma_2 \in \mathscr{C})


* The metric :math:`\rho` is complete on :math:`\mathscr{C}`
* Convergence in :math:`\rho` implies uniform convergence on compacts

In consequence, :math:`K` has a unique fixed point :math:`\sigma^* \in \mathscr{C}`
and :math:`K^n c \to \sigma^*` as :math:`n \to \infty` for any :math:`\sigma \in \mathscr{C}`

By the definition of :math:`K`, the fixed points of :math:`K` in :math:`\mathscr{C}` coincide with
the solutions to :eq:`eqeul1` in :math:`\mathscr{C}`

.. only:: html

    In particular, it :download:`can be shown </_static/pdfs/pi2.pdf>` that the path :math:`\{c_t\}`
    generated from :math:`(a_0,z_0) \in S` using policy function :math:`\sigma^*` is
    the unique optimal path from :math:`(a_0,z_0) \in S`

.. only:: latex

    In particular, it `can be shown <https://lectures.quantecon.org/_downloads/pi2.pdf>`__ that the path :math:`\{c_t\}`
    generated from :math:`(a_0,z_0) \in S` using policy function :math:`\sigma^*` is
    the unique optimal path from :math:`(a_0,z_0) \in S`

**TL;DR** The unique optimal policy can be computed by picking any
:math:`\sigma \in \mathscr{C}` and iterating with the operator :math:`K` defined in :eq:`eqsifc`

Value Function Iteration
-----------------------------


The Bellman operator for this problem is given by

.. math::
    :label: eqbop

    Tv(a, z)
    = \max_{0 \leq \sigma \leq Ra + z + b}
    \left\{
        u(c) + \beta \int v(Ra + z - \sigma, \acute z) \Pi(z, d \acute z)
    \right\}


We have to be careful with VFI (i.e., iterating with
:math:`T`) in this setting because :math:`u` is not assumed to be bounded

* In fact typically unbounded both above and below --- e.g. :math:`u(c) = \log c`
* In which case, the standard DP theory does not apply
* :math:`T^n v` is not guaranteed to converge to the value function for arbitrary continous bounded :math:`v`

Nonetheless, we can always try the popular strategy "iterate and hope"

We can then check the outcome by comparing with that produced by TI

The latter is known to converge, as described above


Implementation
-----------------

.. index::
    single: Optimal Savings; Programming Implementation

Here’s the code for a class called ConsumerProblem that stores primitives, 
as well as an operator factory which returns

* `T`, a function which implements the Bellman operator :math:`T` specified above

* `get_greedy` function, which finds the maximizers of the Bellman operator :math:`T`

* `K`, a function which implements the Coleman operator :math:`K` specified above


.. code-block:: python3

    import numpy as np
    from quantecon.optimize import brent_max, brentq
    from interpolation import interp
    from numba import njit, prange
    import matplotlib.pyplot as plt
    

    class ConsumerProblem:
        """
        A class that stores primitives for the income fluctuation problem.  The
        income process is assumed to be a finite state Markov chain.
        """
        def __init__(self, 
                     r=0.01,                        # Interest rate
                     β=0.96,                        # Discount rate
                     Π=((0.6, 0.4), 
                        (0.05, 0.95)),              # Markov matrix for z_t
                     z_vals=(0.5, 1.0),             # State space of z_t
                     b=0,                           # Borrowing constraint
                     grid_max=16,
                     grid_size=50,
                     u=np.log,                      # Utility function
                     du=njit(lambda x: 1/x)):       # Derivative of utility

            self.u, self.du = u, du
            self.r, self.R = r, 1 + r
            self.β, self.b = β, b
            self.Π, self.z_vals = np.array(Π), tuple(z_vals)
            self.asset_grid = np.linspace(-b, grid_max, grid_size)
            
                    
    def operator_factory(cp, parallel_flag=True):
        """
        A function factory for building the Bellman operator,
        a function that computes greedy policies, as well as
        the Coleman operator.

        Here cp is an instance of ConsumerProblem.
        """
        # === Simplify names, set up arrays === #
        R, Π, β, u, b, du = cp.R, cp.Π, cp.β, cp.u, cp.b, cp.du
        asset_grid, z_vals = cp.asset_grid, cp.z_vals
        γ = R * β

        @njit
        def objective(c, a, z, i_z, v):
            """
            The right hand side of the Bellman equation.
            """
            val = u(c)
            for i in range(len(z_vals)):
                val += β * interp(asset_grid, v[:, i], R * a + z - c) * Π[i_z, i]

            return val

        @njit(parallel=parallel_flag)
        def T(v):
            """
            The approximate Bellman operator, which computes and returns the
            updated value function.
            """
            v_new = np.empty_like(v)

            for i_a in prange(len(asset_grid)):
                a = asset_grid[i_a]
                for i_z in prange(len(z_vals)):
                    z = z_vals[i_z]
                    c_star, v_star, _ = brent_max(objective, 1e-8, R * a + z + b, args=(a, z, i_z, v))
                    v_new[i_a, i_z] = v_star

            return v_new
        
        @njit(parallel=parallel_flag)
        def get_greedy(v):
            """
            Computes the v-greedy policy of a given function v.
            """
            σ = np.empty_like(v)

            for i_a in prange(len(asset_grid)):
                a = asset_grid[i_a]
                for i_z in prange(len(z_vals)):
                    z = z_vals[i_z]
                    c_star, v_star, _ = brent_max(objective, 1e-8, R * a + z + b, args=(a, z, i_z, v))
                    σ[i_a, i_z] = c_star

            return σ
        
        @njit
        def euler_diff(c, a, z, i_z, σ):
            """
            The difference of the left hand side and the right hand side
            of the Euler Equation.
            """
            lhs = du(c)
            expectation = 0
            for i in prange(len(z_vals)):
                expectation += du(interp(asset_grid, σ[:, i], R * a + z - c)) * Π[i_z, i]
            rhs = max(γ * expectation, du(R * a + z + b))

            return lhs - rhs

        @njit(parallel=parallel_flag)
        def K(σ):
            """
            The approximate Coleman operator.

            Iteration with this operator corresponds to time iteration on the Euler
            equation.  Computes and returns the updated consumption policy
            σ.  The array σ is replaced with a function cf that implements
            univariate linear interpolation over the asset grid for each
            possible value of z.
            """
            σ_new = np.empty_like(σ)
            for i_a in prange(len(asset_grid)):
                a = asset_grid[i_a]
                for i_z in prange(len(z_vals)):
                    z = z_vals[i_z]
                    c_star = brentq(euler_diff, 1e-8, R * a + z + b, args=(a, z, i_z, σ)).root
                    σ_new[i_a, i_z] = c_star
                                    
            return σ_new

        return T, K, get_greedy


Both `T` and `K` use linear interpolation along the asset grid to approximate the value and consumption functions

The following exercises walk you through several applications where policy functions are computed

In exercise 1 you will see that while VFI and TI produce similar results, the latter is much faster

Intuition behind this fact was provided in :doc:`a previous lecture on time iteration <coleman_policy_iter>`

Exercises
=============


Exercise 1
------------

Next let's consider how the interest rate affects consumption

Reproduce the following figure, which shows (approximately) optimal consumption policies for different interest rates

.. figure:: /_static/figures/ifp_policies.png
   :scale: 100%

* Other than `r`, all parameters are at their default values
* `r` steps through `np.linspace(0, 0.04, 4)`
* Consumption is plotted against assets for income shock fixed at the smallest value

The figure shows that higher interest rates boost savings and hence suppress consumption



.. _ifp_ex3:

Exercise 3
------------

Now let's consider the long run asset levels held by households

We'll take `r = 0.03` and otherwise use default parameters

The following figure is a 45 degree diagram showing the law of motion for assets when consumption is optimal

First we will write a `solve_model` function which iterates Coleman operation to find :math:`\sigma^*`


.. code-block:: python3

    def solve_model(cp,
                    use_parallel=True,
                    tol=1e-4,
                    max_iter=1000,
                    verbose=True,
                    print_skip=25):
        
        u, β, b, R = cp.u, cp.β, cp.b, cp.R
        asset_grid, z_vals = cp.asset_grid, cp.z_vals
        
        # initial guess of V and σ
        V = np.empty((len(asset_grid), len(z_vals)))
        σ = np.empty_like(V)
        for i_a, a in enumerate(asset_grid):
            for i_z, z in enumerate(z_vals):
                c_max = R * a + z + b
                σ[i_a, i_z] = c_max
                V[i_a, i_z] = u(c_max) / (1 - β)

        _, K, _ = operator_factory(cp, parallel_flag=use_parallel)

        i = 0
        error = tol + 1

        while i < max_iter and error > tol:
            σ_new = K(σ)
            error = np.max(np.abs(σ - σ_new))
            i += 1
            if verbose and i % print_skip == 0:
                print(f"Error at iteration {i} is {error}.")
            σ = σ_new

        if i == max_iter:
            print("Failed to converge!")
            
        if verbose and i < max_iter:
            print(f"\nConverged in {i} iterations.")

        return σ_new

        
    m = ConsumerProblem(r=0.03, grid_max=4)
    T, K, get_greedy = operator_factory(m)

    σ = solve_model(m, verbose=False)
    a = m.asset_grid
    R, z_vals = m.R, m.z_vals

    fig, ax = plt.subplots(figsize=(10, 8))
    ax.plot(a, R * a + z_vals[0] - σ[:, 0], label='Low income')
    ax.plot(a, R * a + z_vals[1] - σ[:, 1], label='High income')
    ax.plot(a, a, 'k--')
    ax.set(xlabel='Current assets', 
           ylabel='Next period assets',
           xlim=(0, 4), ylim=(0, 4))
    ax.legend()
    plt.show()



The blue line and orange line represent the function

.. math::

    a' = h(a, z) := R a + z - \sigma^*(a, z)


when income :math:`z` takes its high and low values respectively

The dashed line is the 45 degree line

We can see from the figure that the dynamics will be stable --- assets do not
diverge

In fact there is a unique stationary distribution of assets that we can calculate by simulation

* Can be proved via theorem 2 of :cite:`HopenhaynPrescott1992`

* Represents the long run dispersion of assets across households when households have idiosyncratic shocks


Ergodicity is valid here, so stationary probabilities can be calculated by averaging over a single long time series

* Hence to approximate the stationary distribution we can simulate a long time series for assets and histogram, as in the following figure

.. figure:: /_static/figures/ifp_histogram.png
   :scale: 100%

Your task is to replicate the figure

* Parameters are as discussed above

* The histogram in the figure used a single time series :math:`\{a_t\}` of length 500,000

* Given the length of this time series, the initial condition :math:`(a_0, z_0)` will not matter

* You might find it helpful to use the ``MarkovChain`` class from ``quantecon``



.. _ifp_ex4:

Exercise 4
------------

Following on from exercises 2 and 3, let's look at how savings and aggregate asset holdings vary with the interest rate

* Note: :cite:`Ljungqvist2012` section 18.6 can be consulted for more background on the topic treated in this exercise

For a given parameterization of the model, the mean of the stationary distribution can be interpreted as aggregate capital in an economy with a unit mass of *ex-ante* identical households facing idiosyncratic shocks

Let's look at how this measure of aggregate capital varies with the interest
rate and borrowing constraint

The next figure plots aggregate capital against the interest rate for `b in (1, 3)`


.. figure:: /_static/figures/ifp_agg_savings.png
   :scale: 100%

As is traditional, the price (interest rate) is on the vertical axis

The horizontal axis is aggregate capital computed as the mean of the stationary distribution

Exercise 4 is to replicate the figure, making use of code from previous exercises

Try to explain why the measure of aggregate capital is equal to :math:`-b`
when :math:`r=0` for both cases shown here

Solutions
==========




Exercise 1
----------

.. code-block:: python3
    
    r_vals = np.linspace(0, 0.04, 4)

    fig, ax = plt.subplots(figsize=(10, 8))
    for r_val in r_vals:
        cp = ConsumerProblem(r=r_val)
        σ = solve_model(cp, verbose=False)
        ax.plot(cp.asset_grid, σ[:, 0], label=f'$r = {r_val:.3f}$')

    ax.set(xlabel='asset level', ylabel='consumption (low income)')
    ax.legend()
    plt.show()


Exercise 3
----------

.. code-block:: python3
    
    from quantecon import MarkovChain

    def compute_asset_series(cp, T=500000, verbose=False):
        """
        Simulates a time series of length T for assets, given optimal savings
        behavior. Parameter cp is an instance of ConsumerProblem
        """
        Π, z_vals, R = cp.Π, cp.z_vals, cp.R  # Simplify names
        mc = MarkovChain(Π)
        σ = solve_model(cp, verbose=False)
        cf = lambda a, i_z: interp(cp.asset_grid, σ[:, i_z], a)
        a = np.zeros(T+1)
        z_seq = mc.simulate(T)
        for t in range(T):
            i_z = z_seq[t]
            a[t+1] = R * a[t] + z_vals[i_z] - cf(a[t], i_z)
        return a

    cp = ConsumerProblem(r=0.03, grid_max=4)
    T, K, get_greedy = operator_factory(cp)
    a = compute_asset_series(cp)
    
    fig, ax = plt.subplots(figsize=(10, 8))
    ax.hist(a, bins=20, alpha=0.5, density=True)
    ax.set(xlabel='assets', xlim=(-0.05, 0.75))
    plt.show()


Exercise 4
----------

.. code-block:: python3
    
    M = 25
    r_vals = np.linspace(0, 0.04, M)
    fig, ax = plt.subplots(figsize=(10, 8))

    for b in (1, 3):
        asset_mean = []
        for r_val in r_vals:
            cp = ConsumerProblem(r=r_val, b=b)
            mean = np.mean(compute_asset_series(cp, T=250000))
            asset_mean.append(mean)
        ax.plot(asset_mean, r_vals, label=f'$b = {b:d}$')
        print(f"Finished iteration b={b:d}")

    ax.set(xlabel='capital', ylabel='interest rate')
    ax.grid()
    ax.legend()
    plt.show()




